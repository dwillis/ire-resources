NICAR 2014, Baltimore
News

Maud Beelman, The Dallas Morning
mbeelman@dallasnews.com,

@maudbeelman

EDITING THE DATA PROJECT
 You can backstop your data reporters/projects even if you’ve never worked with data yourself.
 Don’t be intimidated. Think of databases like filing cabinets full of information that can be
unlocked with the right questions. What do you want to know?
 In general, there are two types of data stories/projects: ones that emanate from the data, and
ones that use data to supplement other reporting. Which is yours?
 Ask early what kinds of data might be available. Beyond the obvious, are there other data sets
available?
 Have others done similar reporting and, if so, what data did they use and how?
 Check IRE/NICAR tipsheets to see if anyone has worked with similar data.
 Read professional/academic literature to identify experts in your area of interest/inquiry
who might have worked with similar data and can advise.
 Data is not magic. Be as skeptical of it as you are with human sources.
 Ask what are the known limitations of or problems with the data. All data are “dirty.” The
question is how dirty.
 Ask who collects the data and for what reason? Is the database a clearinghouse of
unvetted information, or is it targeted, carefully gathered information? This may tell you
something about the reliability or bias of the information.
 Ask what is significant about the data findings. Don’t confuse the sometimes-great effort
it took to get the answer with the importance of the answer.
 You can go narrow and deep, or wide and deep. But the latter takes a lot of time and resources.
So try to focus the analysis as early as possible.
 Ask for a copy of the records layout as soon as the reporters have it so that you can understand
what kinds of queries can be made of the data.
 If there is a “read me” file or an errata sheet that accompanies the data, editors should also read
it.
 Think of your data as concentric circles of information: What can it tell you about a problem
locally, regionally, statewide, nationally? How does your local problem compare to the state?

How does the state compare to the nation? How does it compare internationally?
 Ask your reporters to write a white paper that summarizes their preliminary data findings and
explains their methodology. This is not wasted effort. It helps reveal story lines, holes, new
questions. It serves as the foundation of a story draft and “nerd box.”
 If the reporter is working with data in a spreadsheet, ask for a copy of it. Become familiar with it.
Play around with it; narrow the fields to focus on information you think could form the backbone
of a story. Consult the reporters. Repeat.
 For a story on bridge safety, the data reporter sent me a spreadsheet of the 10 worst
bridges in Texas. Looking at that helped me ask some basic, initial questions:
 Why are there only 250 listings for Texas when there are 254 counties?
 Are we missing data or do four counties have no bridges or no problem bridges?
 Does it make a difference in safety ratings whether or not a bridge is part of a toll road?
 If the reporter is working with a database, familiarize yourself with it, walk through it together.
Don’t just rely on a derivative spreadsheet; you might miss something.
 Make sure you fully understand the methodology and the reasoning behind it. Does it make
sense?
 Ask reporters early and often what worries them about the data?





Is it the data itself?
The study methodology?
Too-eager editors or ones with pre-determined story lines?
Unrealistic deadlines?

 Ask the reporters how they have verified their data analysis.





Did they vet their methodology with a subject matter or other expert?
Did they keep a data diary?
Did they re-import the data from scratch and re-run the entire analysis?
Did they ask others to check their work?

 Ask them for a copy of their data checklist. If they don’t have one, have them create one.
 If you have the luxury of more than one data analyst in the newsroom, ask one to re-check the
other, working independently of the original analysis, or by auditing scripts, reviewing data
diaries; by rechecking each major finding against the original data set.
 Verify what the data is telling you with on-the-ground reporting. [We used Google Earth to
supplement our reporting on neighborhoods surrounding ammonium nitrate plants in Texas.
Bridges data listed two “bad” bridges that were actually two ends of the same bridge and we’d
found it was already closed for repairs.]

 Share your results with targets early. Give them a chance to attack your data and methodology
and allow enough time to consider their criticisms and, if necessary, rerun your data.
 Learn from your mistakes. When errors occur, figure out how they happened and why, and then
incorporate those lessons learned into a data best practices for your newsroom.

