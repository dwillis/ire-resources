Bernard J. Wolfson
The Orange County Register
(7 14) 796-6977
bwolfson@ocregister.com
HOSPITAL REPORT CARD
SYNOPSIS
We rated the quality of care at 26 acute care hospitals in Orange County,
California, using a four star system. We based the ratings on seven measures
created by the Register with advice from health care experts around the
country. We then calculated the average prices at each of the hospitals and
compared them to report card performance.
MAJOR FINDINGS
1.) There was no correlation between how much hospitals billed and their
report card ratings
2.) The top four hospitals were nonprofits; the bottom four were forprofits
3.) Tenet Healthcare Corp., the largest hospital operator in Orange
County, offered mediocre quality at the highest prices in the county
PRIMARY COMPUTER TOOLS USED
Excel for crunching the data and computing overall ratings; Microsoft
Access for extracting billing data from over 3 million patient records
COST
About $1,300, including $800 for four years of patient discharge records;
$500 fee for consultant who risk-adjusted our mortality and complication
data. This was a GREAT deal. Other databases also cost money, but we
already had them in hand.
TIME FROM CONCEPTION TO PUBLICATION
A little over 11 months.
OBSTACLES
I.) A paucity of ready-to-use hospital quality indicators (especially ones that
are available for all hospitals rather than just a handful of hospitals).

Solution: We crunched them from scratch after scouring public and in-house
databases and paper records for everything we thought said something about
quality of care. We ended up with seven measures.

11.) What the heck did we know about measuring hospital quality anyway?
There are no universally accepted standards on what constitutes quality of
care or how to measure it, or on the value of the measures we created. And
not only that: our lack of statistical expertise meant we had a steep learning
curve in trying to crunch our measures into an overall index, or even
compare hospitals with each other on the individual measures.
Solution: Outsource! We hired Michael Pine, a Harvard-trained cardiologist
turned medical statistician, to risk adjust our death and complication rates,
giving us a stamp of credibility. We found ten prominent health care experts
willing to recommend weights for our measures. We consulted regularly
with statisticians on the best methodology. We did several different versions,
like water seeping through a volcanic filter, before hitting on the one that
worked best.
111.) Internal resistance and uncertainty over which way to go. Do we do a
full report card with composite (ie, overall) rating or not? This is inevitably a
big, messy, complicated, maddening, time-consuming project with lots of
nuances and subjectivity and caveats - which editors hate -- and more
importantly, it took us off dailies!
Solution: We decided to be as ambitious and "consumer friendly" as we
could. Hence the full blown report card. That wouldn't be feasible If you
live in a sparsely populated area with few hospitals. You can just produce
performance data it out there for readers to see without "ratings." On dealing
with editors: feed the machine often enough to keep editors at bay while still
working on the report card on a semi-full-time basis. Break down fairly
sophisticated statistical methods to readily understandable bytes and put
them in terms that editors (who are busy, not stupid) will understand with
minimal effort: ie, "this hospital has highest death rate;" "that hospital is a
four star hospital."

IV.) Lack of space in the paper to do justice to complexity of subject.
So1ution:A comprehensive Web package, with detailed explanations of
measures, their pros and cons; raw data behind each measure; responses
fiom hospitals and fiom hospital lobby.

V.) This project will take you longer than you think, and data is constantly
being updated, rendering your measures more and more obsolete. You could
spend your whole time updating data and never finishing.
Solution: Establish cutoff points for each measure (they will differ), and
accept that some of your measures will be outdated by the time you go to
print. In one case, Kaiser Permanente had a new JCAHO survey with a
dramatically higher score which would have made it a four-star hospital, but
it was too late. We footnoted such cases in the paper and on the web.

VI.) Extreme hospital hostility. The local hospital trade group wrote letters,
copying the publisher, questioning our motives, our ability, and every single
measure we proposed to use
Solution: Get out your flak jackets. Beyond that, we chose the course of total
openness and honesty. We gave all the hospitals all of the data - our full
Excel spreadsheet with all the fonnulas and computations -- many weeks in
advance. We asked for their input, for any corrections they thought needed
to be made, and for written responses, which we promised to publish in full
on our Web site (and did). We also scheduled visits to every hospital that
would have us and met with their executives, and listened to their concerns
about the report card. These concerns were reflected in the story or the
accompanying notes, when warranted. We provided lots of meticulous
explanation in the story and on the web of where we got the measures, the
raw data behind them, what the pros and cons are, what journal articles say,
and why we used them.

SOME ONLINE SOURCES
The Leapfrog Group: A consortium of large employers and other health
care purchasers who measure hospital performance on a small group of
standards they believe correlates to good care (www.leapfroggroup.org)
Joint Commission on Accreditation of Healthcare Organizations: The
nation's principal hospital credentialing organization. Website contains
scores on numerous criteria, but survey methods changed in 2004 and some
hospitals have not yet been surveyed under new regime (www.jcaho.org)
PEP-C: A voluntary survey ofpatients about their experiences in California
hospitals. Number ofparticipating hospitals has grown in recent years, but
not all are there (www.calhospitals.org)

National VoluntaryHospital Reporting Initiative: Hospitals nationwide
have agreed to report theirperformance on ten measures under a quality
measuringprogram launchedjointly by the hospital lobby and CMS.
Measure are all about 'process, not outcomes, but it is evolving. Raw data
can be seen at www.cms.hhs.gov/quality/hospital.By April I , it will be
available to general consumers at www.medicare.gov.
"

Office of Statewide Health Planning and Development: For California
hospitals, this is a goldmine of information onfinances, hours worked by
nurses and other healthcareprofessionals, and specialties -- ie, acute vs.
long term care vs. detoxijication. OSHPD also publishes outcomes of
coronary bypass operations, which all hospitals performing them must
report by state law (www.oshpd.cagov). OSHPD also collects discharge
recordsfor every patient dischargedfiom every hospital in the state -- over
3 million a year. These data are an excellent source of information on
billing patterns and medical outcomes. You must buy itfiom OSHPD on
CDs, and need tojump through hoops to overcome their HPPA concerns.
You'll Microso$ Access or some other high-power data management
software to make any sense of it. Check to see ifyour state has patient
discharge records.
Consumers checkbook: A nonprofit advocacy group publishes report cards
on hospitals, as well as doctors and HMOs
(www.consumerscheckbook.org).
The 0.C. Register's hospital report card:
(http://www.ocregister.c o d n ews/2003/hospitaIs/reportcards.shtml)

Page 1 of 2

Here's how we did it, and how it can help you

ISITE SEARCH

I-@ TOP NEWS IN TODAY'S REGISTER

Browse past 7 days
Advanced search

Classifieds
Flnd It. Sell It.
Car I Job I Home I More
> Place an ad

Marketplace
Shopping and more

.

Newspaper ads
Coupons
Buy our photos

Sections
E-REGISTER
The print edition online
E-REGISTER ARCHIVE
E-COMMUNITIES
Weekly newspapers
TODAY'S FRONT PAGE
HOME PAGE
REGISTER TOP NEWS
BUSINESS
COLUMNS
COMMENTARY
EDUCATION
ENTERTAINMENT
FOOD B WINE
HEALTH B FAMILY
INVESTIGATIONS
LIFE, ETC.
MULTIMEDIA
NATION &WORLD
OBITUARIES
REGION & STATE
SPECIAL FEATURES
SPORTS
WEATHER

Community news
Noticias en Espahol

Interactive tools
Discussion boards
Financial tools
Get a map
Get directlons

Sunday, November 16,2003

Here's how we did it, and how it can help you
A

By BERNARD J. WOLFSON

Will

The Orange County Register

youl
e

The hospital report card published in today's Orange
County Register contains information to help readers
make informed choices about their health care.
In constructing its hospital report card, the Register
interviewed experts in the field of assessing healthcare quality, researched academic studies and trade
journals, and talked with local health- care executives
and experts.

TREATMENT: Clalre Shannon, an RN
in Intensive care at Tustin Hospital,
tends to kldney patient Lars Wanberg.
MARK RIGHTMIRE, THE ORANGE
COUNTY REGISTER

An extensive search of public documents was done.
These included patient discharge records and financial reports filed with the Office of
Statewide Health Planning and Development, civil court records, California Medical Board
disciplinary actions, hospital physician lists and Web sites, and survey results from the
Joint Commission on Accreditation of Healthcare Organizations.
Next, the Register hired Michael Pine and Associates, a Chicago health-consulting firm, to
compute risk- adjusted mortality and adverse-outcome rates based on California patient
discharge records from 1998 to 2000 - the most recent available at the time Pine did the
analysis.
Only acute-care general hospitals are compared in the report card. All 26 have
emergency rooms. Pediatric and long-term rehabilitation hospitals were excluded, as
were psychiatric and substance- abuse facilities.
The report card consists of seven measures. To
compute a composite score, each measure needed a
weight to reflect its importance in ranking hospitals.
The Register assembled 10 experts to help weight the
measures.

THE REPORT CARDS

The panelists rated each measure on a scale of zero to
10. Zero meant no significance; 10 was the highest
significance. The experts' ratings for each measure
were averaged, and those averages were used to
.- - - - -- - - - - - - FindI out how your hospital scor
calculate the weights that went into the scores.

Here's how we did it. and how it can he111 vpu
Register in education
Site feedback
Subscr~betoday

talhnb
Media partners

-

MSNBC
0CExcels1or.com
myOC.com
KPCC
KOCE

--

--- -

- -

expressed as a positive or negative number. Those numbers were then multiplied by the
weight assigned to the measure. Finally, these weighted scores (seven for each hospital)
were added together to derive the overall score.
The highest-ranking hospitals (four stars) are the farthest above the average. The lowestranking hospitals (one st&) are the farthest below average. Three-star ho;pitals
are
above the average; two-star hospitals are below.
Readers should keep in mind that the seven measures and overall rating give a broadbrush look at quality but do not contain the level of detail that might be useful to individual
patients with specific needs. Readers should consult other resources for information
specific to their medical conditions.
The report card does not compare hospitals against any absolute standard of quality,
because none exists. For example, while it is widely accepted that a lower death rate is
better than a higher one, nobody can say how low is "good" or how high is "bad." Instead,
the report card shows how the hospitals stack up against each other.
No single set of measures can fully assess the broad range of complicated functions
hospitals perform. So the Register is publishing three other indicators alongside its report
card measures. One is the Leapfrog survey, compiled by a group of larger employers.
Leapfrog asks hospitals to report on several criteria affecting patient safety. Another is the
Patients' Evaluation of Performance in California, or PEP-C, the nation's largest publicly
reported survey on patients' opinions about hospitals. The third is the hospital report card
recently released by Pacificare Health Systems Inc., the Cypress managed- care
company.
For readers in the midst of choosing health-care coverage for 2004, this information
should help assess area hospitals. Patients generally choose doctors or medical groups
rather than hospitals, and those choices will restrict the hospitals available to them. As
consumers weigh which doctor or medical group to choose, it's important to leam which
hospitals they are associated with.

Copyright 2004 The Orange County Register I Privacy policy ( User agreement

w

Freedom Commun~cations.Inc.

DI

