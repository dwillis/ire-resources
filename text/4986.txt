Algorithmic accountability panel
#NICAR17
Description
Algorithms are increasingly used throughout the public and private sectors, making decisions that
impact people’s lives in myriad ways. Algorithmic accountability reporting is an emerging set of
methods for investigating how algorithms exert influence and power in society. In this session we’ll
detail concrete investigations in this domain and discuss strategies, methods, and techniques for
pursuing algorithmic accountability reporting.

Speakers
●

●

●

●

Julia Angwin (@JuliaAngwin) is a senior reporter at ProPublica. From 2000 to 2013, she
was a reporter at The Wall Street Journal, where she led a privacy investigative team that
was a finalist for a Pulitzer Prize in Explanatory Reporting in 2011 and won a Gerald Loeb
Award in 2010. Her book "Dragnet Nation: A Quest for Privacy, Security and Freedom in a
World of Relentless Surveillance," was published by Times Books in 2014.
Sam Corbett­Davies (@scorbettdavies) is a Fulbrighter from New Zealand studying
towards his Ph.D. in computer science at Stanford. Sam's research applies machine
learning and statistics to questions of politics and policy. He is currently studying what it
means for an algorithm to be fair, especially in the context of risk assessments in the
criminal justice system. Before that he was awarded a Knight Foundation grant to study
police officer behavior at traffic stops.
Nick Diakopoulos (@ndiakopoulos) studies computational and data journalism with an
emphasis on algorithmic accountability, data visualization, and social computing. He
received his Ph.D. in Computer Science from the School of Interactive Computing at
Georgia Tech where he co­founded the program in Computational Journalism. Before
UMD, he worked as a researcher at Columbia, Rutgers, and CUNY studying the
intersections of information science, innovation and journalism.
Moderator: Greg Linch (@greglinch) works as a data developer for McClatchy and its 30
local newsrooms around the U.S. He previously worked at The Washington Post in a
variety of roles, such news developer and local data projects editor. Greg has taught as an
adjunct at Georgetown University and Northwestern's Medill D.C. campus.

Topics
●

●
●
●
●
●
●
●
●

Different types of news stories about algorithms (e.g. discrimination, censorship, privacy,
denial of fundamental rights, false positives vs. false negatives, human interventions in
algorithms, violation of law or social norm, exacerbation of existing issues)
Algorithms as sociotechnical systems, i.e. feedback loops with people
FOIA of algorithms
How to evaluate an algorithm? Methods for studying algorithms: auditing, critical analysis,
reverse engineering
How to be ethical (e.g. transparent) with the algorithms you use in your own newsroom
investigations or tools
Limits of story model for covering algorithms (they are constantly changing!)
Difficulties with defining “bias,” “fairness,” “risk” and other qualitative terms. What is legally
defensible or not?
Solutions or ways to address lack of algorithmic transparency?
What’s next? Algorithms: Out. AI: In.

Resources
●
●
●
●
●
●
●

AlgorithmTips.org
Algorithmic Accountability & Transparency ­ Nick Diakopoulos
Algorithmic Accountability: On the Investigation of Black Boxes ­ Nick Diakopoulos
Investigating algorithms ­ CJR
Dragnet Nation ­ Julia Angwin
Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms
Auditing Algorithms ­ Northeastern University

Examples
●
●
●
●
●
●

Machine bias series ­ ProPublica
Websites Vary Prices, Deals Based on Users' Information ­ WSJ
Sex, Violence, and Autocomplete Algorithms ­ Slate
Why Google Search Results Favor Democrats ­ Slate
How Google Shapes the News You See About the Candidates ­ Slate
Uber seems to offer better service in areas with more white people. That raises some
tough questions. Washington Post.

