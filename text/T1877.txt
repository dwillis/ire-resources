Start-to-Finish CAR

Step 3: The Data Is In—Now
What?

PHASE I: THE FIRST PASS
Sarah Cohen, The Washington Post
cohensh@washpost.com; 202-334-6259
You’ve had a good daily story, or gotten a good tip and worked your way through the bureaucratic
morass of public records. The data is on its way. It’s sitting in your email in a huge attachment, the CD is
being picked up or the tape was sent out for reading. Do the data dance now. You might never get the
chance again.
Early reporting splits into two forms -- the nerd work and the reporting work. Don’t shortchange either
one as soon as you get the data.
1. Did you get what you asked for? Is it in the form you expected? Did you get all the columns (fields)
you think you were entitled to? Did you get about the right number of records? Are there any big holes?
Some of this you won’t know until you run some reports on your data. You might have missing years,
missing people or missing cases.
2. Is it in the form you expected? Increasingly, “helpful” public affairs offices are compiling reports or
importing your database into an Excel spreadsheet. Don’t let this happen - if there are mistakes, you want
to be the one to make them.
3. Regroup and check the story. By the time you get data, you've usually moved ahead on your story
and it no longer resembles the original tip. Look at the data you got in a new light -- how would it help
you document the newer ideas? Does the original story still work now that the data has arrived? One big
problem in database work is that, if you limited your original request too much, you may not have the
data you need now to move ahead. It's a good reason to ask for everything, not just what you think you'll
need.
4. Look for the impossible. Run early queries to find examples that should never happen -- old people
going to high school, children with driving infractions, convictions without charges. Report them out.
These might lead you to wrongdoing or point out errors -- either way, you want to know.
5. Look for the illegal or improbable. Closely related to #4, but this time you're looking for things that
the rules say should not happen, but might be good stories if they do -- buildings flunking inspections but
getting occupancy permits; tickets wiped out without being paid or contested, repeat offenses without
punishment. Report them out. They might be data errors, they might be stories. Either way, they'll help
you know what you can do with the data.
5. Make the first (of many) reality checks. Look up cases you've already reported out -- the day story
that prompted your investigation, or a tip that a source led you to believe would make a good story. How
does it look in the data? How would you find more? Does the data reflect the real world? How can you
distinguish these newsworthy cases from the mundane? Look for the M-O.
6. Make an "audit trail" plan NOW. Resist the urge to start correcting mistakes you stumble on in the
data. Instead, decide how you will document changes and updates you make, and whether you want to
correct errors for some when you can't for all. Key to this is making sure that every table has a unique
identifier that can be retraced if you have to go back to the original data or work with an updated copy
from an agency. Sometimes it's just a matter of assigning a sequential number to each record as it's
imported.
Consider how much "hand work" and pointing-and-clicking you want to do (rather than programming). If
you do much, document it profusely. You will need it.

7. Review the basics. Go back to the investigative reports from the GAO, inspector generals, auditors or
even academic papers to see how they have used similar data, how they identified cases. Look at the data
for anything they missed, or review the data to see if you can repeat their work.
8. Interview (or re-interview) the nerd at the agency. Now that you have the data, it is often much
easier to get the agency to allow you to talk with the person who created the database for you. (Now, you
just have "technical" questions on what you got.) Sit down with the expert -- ask for advice, and ask if
there are any fields you failed to get that you need. Now that you have this, you can often just get any data
you forgot to ask for directly, treating it as a "clarification" of your original request.
9. Talk with your editor about your goal. The key decision you will have to make early in this process
is whether you will use your database as a source of leads for reporting, a source of statistics, or both. If
you need the statistics, look carefully at the flaws in the data and decide if they are acceptable.
Talk with your editor about the difference -- If it's OK to say "at least 10 cases were confirmed", then you
don't need stats. If you need to say "the agency dropped one-third of its cases" then you do. Evaluate the
data both ways. Data impossible to use for statistics if often great for story leads.
10. Look for complementary data NOW. Maybe the data you'd hoped for isn't in the data you got.
Maybe you can find it elsewhere. Start those public records requests now.
11. Draft the strongest sentence you would hope to write. Once you've written your dream sentence, go
back and see whether the data would be able to document it. Keep changing the sentence until you find
one that can be proven or disproven with the data. Decide how much work it would take and how many
have to be reported out to let you write it.
Don't fill in the numbers now in your sentence, but make sure you know how many are "enough", and
how pervasive a trend must be to be newsworthy. Ten murderers who escaped from halfway houses might
be enough. Ten contracts with the county executive's pals might not be.

PHASE II: LAB TO FIELD AND BACK AGAIN
Rose Ciotta, The Philadelphia Inquirer
rciotta@phillynews.com; (215) 854-5024
By this point, reporting is underway. The team has questions to answer and data to work with. Early
reporting indicates you are on the right track. You have assembled a team that is ready to dig for facts
from data, documents and sources. As a manager, your job is to keep the project focused on the goal. As
a reporter, your job is to move the story forward. Does the proof match your hypothesis?
1. Reality Check: Testing data on the street. How does the data analysis match up with what you are
hearing from people sources? Look for the people, the place, the circumstances revealed by the data
2. Data Mining: Interviewing your data as a continuing source throughout the project. Use what you
learn from people and other sources to get even more information from the data.
3. Developing Sources: Include those who work with the data. They may tell you about data you didn’t
know existed or help you interpret your results.
4. Interviewing with Power: Use the information culled from the data to dig deeper into the subject. Be
strategic when conducting interviews. Don’t overwhelm your subject with all that you know.
5. Find the voices: Sometimes the people can be identified by name through the data.
Often, they cannot. Do reporting to locate the people who give voice to the information you are coming
up with.
6. Know when to change gears: If your reality checks show problems with your hypothesis, be ready to
recast the project or even to kill it.
7. Secondary Data: Once you score the key datasets, ask early for companion data. Build in time for
acquiring data. At the same time, evaluate every database you go after so you aren’t spending all of your
time negotiating for data.
8. Moving in Sync: Sources and documents become a check on what you are learning from the data and
vice versa.
9. Keeping Track: Start a system early (especially when working on a team) of outlines, sharing notes
and retrieving key interviews. Create a special factoids file for facts culled from the data analysis. Ask for
memos or updates on reporting progress.
10.Plan Early for Photos/Graphics/Maps/Online: Even if you don’t know what your story/project will
conclude, get photo/graphics/mapping/online in gear early. You may need to acquire special software i.e.
Spatial Analyst if you are doing a density map, for example.
11. Details for Storytelling: People, setting, mood, atmosphere, descriptions, locations. These are the
bits of information you can only get from being there. The data may lead you to the neighborhood, the
accident location, the school, or the person. Only you can paint the picture in words of what you saw.
Think ahead to the type of story you plan to write.
12. Write, Write, Write: Write as you go especially if the reporting extends over months. If you do a key
interview with a victim’s family, for example, write it as soon as you can even if you don’t know whether
they will be a key or minor player in your story. Editors should read what reporters are writing so you
know what they are coming up with.
13. Data Selection: In the end, limit the numbers in the text to those required to tell the story. Leave the
rest to graphics or maps. Avoid jargon. Step away from the database labels to describe your analysis.

Spare the readers details on the fact that you did a computer analysis or how you did it. Save those details
for the nerd box or project explainer.
14. Create a story budget. As soon as the reporting allows, sketch out parts with graphics and
photography. If publication is targeted for a certain time or event, develop a back-out schedule so you
have sufficient time to report and write. Coordinate deadlines for stories, photos, graphics, online.
15.Keep Higher Level Editors Informed. If the editor expects a one-month effort, let him know if you
have run into a snag that will delay your progress. Also, consult often on the scope of your reporting.
Don’t surprise her with a five-part series if she’s expecting a Sunday take-out.

PHASE 3: GETTING THE CRITICAL SCRUTINY
Christopher Schmitt, U.S. News and World Report
cschmitt@usnews.com; (202) 955-2032
Our impulse, and common practice in newsrooms, is to closely hold the information we gather and
develop until it's ready for publication. But in CAR work, that can be just the wrong way to go.
That's because:
1) Our data analysis often puts us in unexplored territory, OR
2) Although we're clever, we're often not as expert as, well, the experts, OR
3) Both.
Often, we're essentially doing social science-style research, akin to studies or dissertations.
So, in keeping with that theme, consider using a variant of the "peer review process"; using experts,
expose your entire process – from idea, to data source, to analysis and results – to critical scrutiny. By
focusing as much on process as on results, this is a large step beyond the customary "get comment on
what we found."
There are always experts to be found; some are too busy or attitude-challenged ("Come back and see me
when you have a Ph.D...") but many others quite willing. (Believe it or not, some are even flattered to be
asked.)
Many, if approached sincerely and responsibly, will be warm to the task, especially if they're leaders in
their field.
Hint: If you talk their lingo, or are working in an area of particular interest, you'll do better. Short of that,
do your homework and be as prepared as you can.
1. Look at professional journals. Beyond the standard methods, professional journals are a great way to
find the leading lights – especially in technical areas.
2. Do it one-on-one or in a group, but the more minds brought to bear on your results, the better.
3. Convene a panel. Invite experts from all sides of an issue to meet. Make a formal presentation of your
project. Ask for discussion, comments, feedback, etc.
4. Get reaction on the record. You need quotes on both sides of what you found. Don't be afraid to
report the negative. Everyone else has to be criticized.
What you get:
1) Bullet-proofing and embarrassment-sparing ("That's bogus because..."), OR
2) Suggestions to make it better ("Did you think of doing it this way...?"), OR
3) Comments and quotes usable in the story, OR
4) Ideally, all of the above.
Laying bare your soul like this can be uncomfortable; you've got to be prepared to take some heat; but
there's little doubt you'll get a better story.
A caveat: The experts, on whatever side, can have their own agendas, too, and that can influence the
feedback they give you. Still, if nothing else, it's expert reaction to which you'll be most vulnerable upon
publication...forewarned is forearmed.
Examples:

U.S. News & World Report recently detailed how the nation's nursing homes – despite cries of
poverty to Congress as operators pled for more federal money – were actually much more profitable than
acknowledged; and that even as patient care remains deeply troubled, operators are frequently engaging in
lucrative self-dealing. The findings were based on an analysis of hundreds of thousands of pages of
financial reports. Before publication, U.S. News prepared a detailed written report of its findings and
methodology, and circulated it to numerous people – policy and health care experts, patient advocates and
the industry itself – for comment and review.
The San Jose Mercury News, in a study of the common practice of plea bargaining in criminal
court cases, documented a strong racial bias. Well before publication, the Mercury News convened a
panel of judges, prosecutors and public defenders to hear a presentation on the findings and to discuss and
critique the results. Comments and suggestions emerging from the panel led the newspaper to pursue
several new areas of inquiry.
ONCE THE DATA IS SOLID, LOOK TO LEVERAGE IT
5. While analyzing a database can yield good results, the real power – and the particular capability
of the computer – is in linking different sets of information, to produce even better, but less-thanobvious results. So be alert for opportunities...any "field" in your data is potentially a way to link up one
file with another. Think of names, unique identifiers, geographic codes...
Example:
When the Mercury News examined the California State Lottery, a significant – but unproven –
criticism was that the lottery exploits the poor, because they play more often and can least afford to lose.
The newspaper obtained lottery sales data broken out by ZIP code, then matched that data against ZIP
code-compiled demographic data, to clearly show that lottery sales were far higher in poorer areas than in
affluent places.

