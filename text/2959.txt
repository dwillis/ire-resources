Analyzing test scores for cheating

Holly Hacker, The Dallas Morning News, hhacker@dallasnews.com
IRE Phoenix, June 2007
State ratings. Teacher bonuses. High-school diplomas. School test scores
determine all of these, so there’s intense pressure to do well. So intense that
some kids or teachers may resort to cheating. Here are some signs to look for:
Similar answers
Students who keep getting the same right and wrong answers on
multiple-choice tests. The more that happens, the less likely it is due to
pure chance.
Huge gains (or drops) in test scores
Schools that have terrible test scores one year and super ones the next.
Or in the same year, a school that bombs math but aces science. Schools
can make steady gains over time, but huge leaps deserve a closer look.
Erasure analysis
A few states have student answer sheets (the forms you bubble in with a
No. 2 pencil) scanned for excessive erasures, which could indicate a
student or teacher changing lots of wrong answers to right ones.
Getting the data
•

Get campus-level test scores from your state or district. Don’t just
settle for the percent of students who passed – get the actual scores
(raw or scale scores) from which the pass rates were derived. This makes
your analysis more detailed and reliable.

•

Ask for student-level data. In Texas, we obtained answer strings for
students, showing how each kid answered each question. With that, we
could look for tests that were so similar that it suggested some type of
collusion. See if students are tracked by classroom (in TX they’re not).

•

If you can get student-level data, consider getting demographic
information too, like gender and socioeconomic status, and whether
students are in special education. But the more detail you get, the
greater the chance that some scores will be suppressed because of
federal privacy laws. It’s a tradeoff.

•

See if your state or district keeps copies of “incident reports” or other
forms that teachers are supposed to fill out if they see or suspect
cheating.

Analyzing and presenting the data
•

Get an expert’s help. For our stories on cheating on multiple-choice
tests, we worked with Prof. George Wesolowsky at McMaster University
in Ontario, Canada. He had developed a statistical program called
SCheck that looks for pairs of students with unusually similar answers
that point to cheating. He ran the program that flagged student pairs,
which we then compiled and analyzed. We also had two other professors
review our findings and Prof. Wesolowsky’s method.

•

Graphics, graphics, graphics. Test scores don’t exactly scream “great
photo potential.” Our stories included graphics of sample test questions,
suspicious answer strings and a map of schools that were heavily flagged
for cheating. We also used social network analysis to show pairs and
groups of students who all had suspiciously similar answers.

Resources
Prof. George Wesolowsky’s site – includes an overview of his program
www.business.mcmaster.ca/msis/profs/wesolo/wesolo.htm
An overview of methods (including Wesolowsky’s) used to detect cheating on
multiple-choice exams, from Prof. Larry R. Nelson, Curtin University of
Technology in Australia
lertap.curtin.edu.au/Documentation/JERM2006.doc
Center for Academic Integrity – now at Duke University, moving to Clemson.
Includes research on the prevalence of cheating in schools and colleges.
www.academicintegrity.org
Steven Levitt (the Freakonomics author) and Brian Jacob found teacher-led
cheating in Chicago schools. The paper is called “Rotten Apples: An
Investigation of the Prevalence and Predictors of Teacher Cheating”
pricetheory.uchicago.edu/levitt/Papers/JacobLevitt2003.pdf
Caveon, a test-security firm. Includes an overview of cheating-detection
methods.
www.caveon.com
Along with The Dallas Morning News, the Philadelphia Inquirer and San
Francisco Chronicle have run big cheating stories. See dallasnews.com,
philly.com and sfgate.com

