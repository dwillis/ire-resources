Maurice Tamman
Atlanta Journal Constitution
(404) 460-7813/mtamman@ajc.com

CAR from start to finish: The data is in – now what?
Interviewing the Data
We’ve all had useful interviews that last for hours. Come publish date, however, that
interview gets distilled to a few paragraphs or even a sentence or quote.
But that does not mean the interview was of limited value. In fact, it can be as important
as any element of the package.
Data is no different: The idea is to distill and re-distill and re-distill until you have
something unadulterated; an essence. It’s similar to the fortification process that is the
difference between jug plunk and 20-year-old X.O Cognac.
We should not be looking for volume. As the database person you should end up
knowing the data intimately and that means knowing its essence.
The reader will not have that benefit. Our job is to make that as easy and palatable as
possible: They will not want to drink an entire jug cheap jug of wine that leaves them
with a hangover.
More likely, they will sniff at the data and if strikes them as too much, they’ll decide
against it. The data is the drink; the reporting and writing is conversation that goes on
between sips.
Being intimate:
Every dataset, like every lover, has limitations; in scope or timeliness or accuracy or
completeness.
But when the data comes, play with it; noodle around. Don’t be afraid that the data
doesn’t obviously fit the premise.
Look for the outliers; play with medians and average, rates; look at those elements over
time or compare them to other geographic areas or demographic groups.
If there are standard indexes used among academics, run those. And don’t be afraid to
challenge some of the expert findings. Often, we are looking to explain the exceptions,
not the rule. And when you think you’ve found an interesting trend, don’t settle. See if
that trend is the same everywhere.

If you’re trying to say crime is up in one area and in the cops are saying it’s because
liquor sales are up in that area, take a broader look. If crime rates are increasing at the
same rate all over, and liquor sales are down everywhere else, there may be a larger,
more important factor influencing crime.
If you can, map it; create quintiles, map those. Overlay other datasets; crime, population,
population growth, real estate sales and value; race and ethnicity; income. You should
have a stable of benchmark data that to overlay on new datasets. And save the new data
sets to be used as an overlay in the future.
And when you are done, you will find holes - limitations
And that’s why it’s so important to consider multiple sources of data. Just as it is rare a
project or package of stories uses one source, so why then should we be satisfied with
one source of data elements?
Some editors may say that identifying the data sources early on is critical, and it is. There
should be short list of theoretical or actual datasets that will be used.
Filling those holes, however, is also important. It’s also an opportunity that opens up
inquiry that might not have been considered. Everyone involved in the project needs to be
aware of what the issues are and everyone needs to think creatively about finding
empirical elements to fill that void.
Recently the Atlanta Journal Constitution published a project examining the lottery
funded HOPE scholarship.
In an ideal world Georgia’s education bureaucracy and the state’s lottery would have
supplied us with datasets that would have listed individual lottery winners (the only way
to measure where players live rather than buy tickets) and each scholarship recipient.
We didn’t get that. Instead, we got the data aggregated totals by zip code.
We had two problems: We had a hypothesis that poor lottery players were subsidizing
middle and upper class suburbanites. We could tell where the HOPE money was going
(wealthy suburban zips) and where the lottery money came from (poor zips).
What we really needed was some way of measuring the affluence of those getting the
scholarships. And who was actually buying the tickets.
So we found illustrative data, if not authoritative data.
We looked at data showing the number of scholarships aggregated by family income
prepared for us by some of the state’s largest universities.

We ended focusing on one university because its student body demographic averages
lined up neatly with macro state demographic averages. And from there we could see the
trend: Those getting HOPE were usually from upper-middle class and better households
and those not getting HOPE were from lower income households.
The lottery sales data was harder, but working and talking with the reporters, we found a
former lottery employee who talked about a market study of lottery players that identified
the most frequent players as the poor.
The supporting data was far from perfect but it supported the initial findings and gave it
additional credibility.
Giving context being fair: The analysis is prepared
Consider the first analysis a draft. Don’t be afraid to share preliminary data. Explain the
flaws, but argue a point of view. Ask yourself what it says and then do battle.
Do battle with editors, academics, reporters and yourself.
University of Massachusetts professor Edward Callabrese did a study of 4,000 academic
articles related biological interaction with chemicals. He found that about 350 of those
articles ignored or discounted the positive affect of those chemicals and focused on the
negative.
Hormosis can be found in other areas too. Take inflation or interest rates; both serve a
useful economic function but are devastating in high doses.
I say that not to suggest that academics should be dismissed, but that we should always
be skeptical; of the premise, of the data, of the motivation for the project, of the reporter,
of the editor, of ourselves.
As much as possible we must be willing to divest ourselves of what we’ve put in or what
the experts are saying. Let the data have its voice.
Shortly after the Census long-form data was released, there was much discussion about
how integrated or diverse different areas of the country had become.
By some measures, Atlanta remained a largely segregated metro area and there were
academics used the dissimilarity index to document the segregation. But long-time
residents of the area seemed befuddled. They knew that when they went to the mall or
supermarket, the shoppers were hodge-podge of races, ethnicities, and immigrants.
We looked of an alternative and opted to look at the ranges of diversity in every tract of
the metro area in 1990 and 2000.

Using the diversity index, pioneered by USA Today, we found that nearly 75 percent of
2000 population lived in moderate to highly diverse neighborhoods. In 1990, about 40
percent of the population lived in moderate to highly diverse neighborhoods.
Both methods were entirely valid, but the second illustrated how groups were sharing
communities, schools, and each others lives more than ever.
Packaging and writing about data:
Once the analysis is complete and the interesting elements have been decanted from the
gigabytes you started with, you will still have a sizable number of numbers.
And there is nothing worse that a story that prattles off numbers endlessly as if the
volume of stats in some way makes the stories more interesting or authoritative. Data
should be in stories but keep those numbers extremely focused.
For each story, write a sentence that summarizes the findings.
For everything else, break out the data into grids and charts; give them a place in the
package where readers, given the contexts of the accompanying stories, can digest them
in an informed way.
When we decided to use the Augusta National as a pretext for examining how the lot of
women had changed, we were faced with mountains and mountains of studies and data.
Clearly, women are doing financially better today than ever. But there are costs and their
gains have been uneven.
It’s a complex issue that different stories dealt with separately.
We decided to tell a story, using graphics, that would take the reader through the project
and lay the empirical foundation for everything; from income growth, gains among
different races and age groups and occupations; we included numbers on how mothers
earned less than their childless female co-workers; how female executive still earn less
tan men and how women vote more but still don’t elect women.
Not only would the package have been very difficult to read if the numbers had been
included in the stories, but it the numbers would have been lost. This graphic gave the
reader an anchor and a reference point.
We have an obligation, especially these days, to give our work authority that is difficult
to refute.
Sophisticated, thoughtful data analysis bridges the gap between academia and the
common man. And in doing so, we lend credibility and clarity to our work where it
counts - with the reader.

