import.io
Getting data from the web, easily.

What is import.io?
●
●
●
●
●

Machine reading the web
Point-and-click UI
Map the data on a web page
Algorithms will turn it into structured data
Real-time through an API

What is import.io? (continued)
●
●
●
●
●

Custom Crawlers
Auto extraction
Authenticated APIs
Cloud scaling
Wide range of integration options

Structure the web

Why structure the web?
● Allows us to analyse data
● Allows us to visualise data
● Easier than copy and paste!

This is our web browser, for data

import.io consists of 4 tools
●
●
●
●

Magic
Extractor
Crawler
Connector

This is our web browser, for data

Everything is available over API

and completely free...

Using import.io Magic and
the import.io Extractor

1

Navigate to the source and copy the URL

2

Paste the URL into Magic

3

The data will be extracted with no need for training - it
also recognises pagination

4

Clicking on “GET API” will copy the API to your My Data
page

5

Clicking on “DOWNLOAD” will download a static CSV

Sometimes we need to
train the tool ourselves

The import.io Extractor
lets you structure a single
page of data

1

Click on Extractor from the dropdown menu in the app

2

Navigate to the source and toggle extraction on

3

We can turn CSS off and JavaScript on

4

Start extracting by clicking on a piece of data. You will
be asked this question

5

Finish adding all of the columns you want and hit DONE

6

Name it and click publish

7

Your API is complete

● Custom XPaths
● Custom Regex
● Updatable in real-time

Using the import.io
Crawler

The import.io Crawler is to be used if
the data sits in many pages. It is, in
effect, an automated extractor

1

Click on Crawler from the dropdown menu in the app

2

Navigate to the source and click on “I’m there!”

3

Detect optimal settings

4

You will be asked this question

5

Finish adding all of the columns you want and hit I’ve got
what I need

6

Add 5 more pages and hit I’m done training

7

Name and upload Crawler

8

Click on Go and your Crawler will run

9

You can see pages getting converted in real-time

10

When your Crawler is finished, click on Upload data

11

You will see all of the converted pages in the dataset page

The import.io Crawler relies on
minimum input
and gives you
maximum output

Using the import.io
Connector

The import.io Connector uses page
interactions, such as searches and
extracts the resulting data. It’s
particularly useful in price comparison
scenarios

1

Click on Connector from the dropdown menu in the app

2

Navigate to the source and click record

3

While in record more, type in your search query and hit
the search button

4

Hit the stop button when you can see all of your results

5

Label the input box by clicking on “Make input”

6

Because there are lots of results, use the multiple result
page

7

If a total result count is present, click on Yes please!

8

If there is more than 1 page, click Yes please! for
pagination

9

Now we need to train the Connector, add another query
into the box

10

It will play back the recording with the new query in and
return different results

11

Train your rows and columns

12

If applicable, train the total results

13

If applicable, go to the second page of results to train the
pagination

14

Time to test the Connector fully - enter a new query

15

Confirm that the data, total result count correct and train
the pagination again

16

Click on I’m done creating tests

17

Name and upload your API

18

You can now query the Connector from the dataset page

That’s how easy it is to
make an import.io
Connector

