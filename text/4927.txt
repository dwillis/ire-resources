Intro to data journalism
2017 New York Watchdog Workshop, CUNY
Agustin “Augie” Armendariz, Reporter, The New York Times
augie@nytimes.com
Intro
Good morning, I’m Augie. I’m a reporter on Sara Cohen’s Computer Assisted Reporting Team
at The New York Times.
I worked at two investigative reporting nonprofits and a regional daily newspaper before landing
at The Times. Rarely have I done single byline stories. I’ve had the great fortune to play for
some really great teams and learn from many smart people along the way.
By dumb luck I was introduced to the National Institute of Computer Assisted Reporting
(NICAR) community at the very beginning of my career and I wouldn’t be here today if not for
the brilliant, kind and generous people of NICAR.
Conferences like this one set me on the path. I was shown in hands-on classes how to use
spreadsheets, databases, GIS tools, how to write computer programs and many other things.
Becoming proficient with some of the skills I learned in these classes helped me find work.
My odd carrier track, working mostly on long term investigative projects as part of a team of
reporters, leads me to believe that team reporting will only become more common and that story
collaborations are the Petri dish in which we will grow the digital newsroom of the future.
Video, radio and print stories all get reported differently so it’s hard to go back and make a radio
or video story from a finished print story. It’s possible that reporters will do everything from
shooting video, recording audio and writing a print piece all by themselves. But I suspect that’s
unlikely to happen. Some unique individuals might do it all, but the majority of the work will
likely need to be team ball.
So from my perspective on the Titanic I think being an effective collaborator is high on the list of
important skills to have.
So that’s who I am. Now a bit on the Computer Assisted Reporting tradition.
The Computer Assisted Reporting Tradition
While the phrase Computer Assisted Reporting might sound nonsensical to the uninitiated ear,
it’s a very useful phrase to describe what the people schooled in this tradition do. The word
reporting is the essential part. When analyzing data it’s never appropriate to do so in isolation.
To crunch the numbers, publish and declare, “the data speaks for itself!”

Data analysis is merely a part of the reporting process and it informs and guides the reporting.
The analysis isn’t the story. It might provide the empirical evidence that becomes the backbone
of the story, but only after much reporting has verified the truth of the analysis. If the real world
turns out to look a lot like what the analysis shows, then we can have some confidence that the
data wasn’t so dirty as to be useless.
Treat your data the way you would treat any other source – with curiosity, skepticism and an
open mind. Never treat your data as if it bequeaths unto you capital “T” Truth.
As ProPublica’s Derek Willis says, the data never gets tired of answering your questions even if
they’re stupid questions. So interrogate it thoroughly. Get to know it really well.
Dirty data to tidy data
I was at a conference in Silicon Valley where Hillary Mason, the chief scientist for Bit.ly at the
time, said, “You’re data is dirty. Get over it.” Or at least something to that effect.
Anyone that works with data for a living knows that there are always format issues,
inconsistencies, natural variations and surprises of all sorts that come up to confound the analyst.
Something on the order of 90% of the analysis is cleaning up and getting to know the data in
preparation for the actual analysis. It’s work intensive, time consuming and never-ending.
But it’s important work and helps the analyst understand how to represent the findings derived
from it accurately. Is it 33.33 (which is a really precise number) or is it about a third?
A statistician by the name of Hadly Wickham was struck by the fact that analysts spend so much
time cleaning data, but talk very little about best practices for cleaning up all this dirty data. So
he wrote a paper called “Tidy Data” in which he said, “tidy datasets are all alike but every messy
dataset is messy in its own way.”
My boss Sarah Cohen loves this quote and introduced me to the concept of “tidy data” and
Wickham’s paper. I’m a big believer in spreading the word. My typical process now is to tidy up
my data and then bring it into Excel for the analysis.
Excel makes it easy to summarize the data (min, max, mean, standard deviation, median,
quartiles, etc), graph the data (the shape of your data matters) and quickly group the data in
different ways using PivotTables. Think of Excel’s PivotTables as your tool to mold your tidy
data many different ways very quickly. They are powerful.
We analyze data to test our hypotheses. Because we are never absolutely certain where our
inquiry will lead us, it’s important to keep your data tidy so that you can look at it many different
ways. Especially ways you never thought of when you started the inquiry.

I encourage you all to read the paper and think about Wickham’s advice for turning dirty data
into tidy data for effective analysis.
http://vita.had.co.nz/papers/tidy-data.pdf
Working with tidy data example – NYPD COMPSTAT reports
Here’s a screenshot of a report based on data. It’s nice to look at, but even though it’s in a
spreadsheet it isn’t data that is useful for analysis. It’s dirty. There’s one file that looks like this
for every precinct in the city.

And here’s what a compiled and cleaned up version of all these reports might look like. The
numbers reflect the year-to-date total for 2015 and 2016 through 12-11-2016.

The data could probably be cleaned up a bit more by collapsing the major felony columns into
one column simply called “felony” (murder, rape, robbery, etc) and another called
“type_of_felony” indicating whether the felony is a property crime or a violent crime.
There are many, many different ways to do the cleaning work. I wrote a computer program using
the python programing language to rip the data out, build the csv file, and associate the correct
borough and section to each precinct. But there are many other ways you could clean up the data
and add information to it. Including entering the data by hand every week or waiting until the
end of the year and entering in the year-to-date figures.
If you get into analyzing data on a consistent basis there are some stupid simple programming
tricks that can save you a lot of time and consternation. And as you get more into writing your
own computer programs you’ll find that many if not most tedious tasks can be turned into a fun
programming puzzle.
Building your support network
Editors oversee reporting and the creation of graphics. But there typically isn’t a formal structure
for managing CAR reporters or news technologists. Most often you’ll need to build your own
informal network of co-conspirators to help you learn new technical skills and accurately wield
them in the service of reporting stories. Not to mention to help you effectively manage your
priorities.
If you are fortunate enough to have an experienced CAR reporter as an editor then you have
someone to turn to and talk issues through with. And a great advocate for what you should spend
time on and what you shouldn’t.
More often you’ll probably need to make an alliance with someone in IT that can get you’re
computer set-up right and maybe even provide you some server space. Or supply you with an old
Mac or PC to use as your server. Maybe you’ll find someone on the business side that’s a

statistician and who is happy to help you interpret things sources send to you or help you do your
own statistical analysis.
There are also plenty of people in the NICAR community that you can call on for advice. Be
guided by their experience and seek out their knowledge. I can tell you that it’s a wonderful
community of very smart people who are willing to help.
Learning how to install and manage relational database management systems like mysql and
postgres, led me to use the free Ubuntu linux operating system because it has an amazing
package management program that makes installing software like this a snap compared to
Windows. Mac OS X is better now, but it used to be equally hard.
Being pushed by my boss early in my career to learn how to do a bare minimum of programming
to execute all of my SQL queries one after another launched me on the path to becoming a semidecent programmer.
Picking up some python with the help of IT colleagues in order to try out this thing called
Django led me to learn a whole lot about how the internet operates. Which prepared me for a
deep dive into how supposedly offshore gambling websites serve customers in the United States.
Being a CAR reporter will require a lifetime of learning new skills and building upon existing
ones. Being among a community of learners will be key to your success.
Resources / Product Placement
I’m a big fan of desk references and my number one desk reference is, “Numbers in the
Newsroom,” by my boss Sarah Cohen. I honestly loved this book before she hired me so I’m not
just trying to curry favor with my boss. For $25 you’ll get a book you’ll use regularly throughout
your caree. $15 for memebrs I believe and in the IRE store I think I saw a PDF e-book version
for $10 too.

“Precision Journalism,” by Philip Meyer. The foundational text for the craft of Computer
Assisted Reporting. Again, the name might sound dated, but it speaks to a long and proud
tradition stretching back to before the age when people carried computers in their pockets.

