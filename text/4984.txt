Hannah Birch (@hannahsbirch) and Clarisa Diaz (@Clarii_D)

User testing
Gathering insight to make better stories

What is user testing and why should we do it?

Our job is to make things people understand.

“I am not my users!”

It all comes down to usability.

Ways to Think About Usability
●
●
●
●
●

Useful: Does it do something people need done?
Learnable: Can people figure out how to use it?
Effective: Does it get the job done?
Desireable: Do people want it?
Delightful: Is using it enjoyable, or even fun?

—via Steve Krug, “Don’t Make Me Think, Revisited.”

Steve Krug’s Definition of Usability
“A person of average (or even below average) ability and
experience can figure out how to use the thing to accomplish
something without it being more trouble than it’s worth.”
—Steve Krug

Steve Krug’s Definition of Usability
“A person of average (or even below average) ability and
experience can figure out how to use the thing to accomplish
something without it being more trouble than it’s worth.”
—Steve Krug

Steve Krug’s Definition of Usability
“A person of average (or even below average) ability and
experience can figure out how to use the thing to accomplish
something without it being more trouble than it’s worth.”
—Steve Krug

Users’ Needs and Goals Are Different
●
●
●

Users won’t tell you their goal is to use a website
They want to use that website to do things: book a
flight, know more about their doctor before surgery
Their actual goals are a step beyond that:
○
○

Have a great vacation
Get healthy and stay healthy

Usability = achieving goals*
*goals may differ. User testing supports them all!

"And then we made some adjustments and we
never had that problem again."—Sisi Wei

You Probably Already Have These Skills
●
●
●
●
●
●

Thoughtful interview prep
Asking open-ended questions
Getting someone to tell you more
Take good notes
Coming up with takeaways
Incorporate feedback into your work

Roadmap for the Next Hour
●
●
●
●
●
●

Intro (you are here)
How to fit user testing into crazy newsroom schedules
Examples of short-term projects
Examples of longer-term projects
Hands-on exercise
Conclusion

Time and Scale

The Nature of the Beast
●
●

Limited time before publishing, particularly daily
stories
Complex organization in producing large projects

Daily Scale

Have a Clear Story
●

What are the one or two points the story or visual needs
to get across? From there the form can take any shape,
but the clarity of the content is the driver for revising
and fine-tuning.

Talk to Non-Journalists (and Non-Designers)
●

●

Find people who have no idea what the story could be
about. In basic usability testing, we just want to know
if our story or visual is communicating clearly.
Cross boundaries and approach people not involved,
they’ll be glad you did.

Listen & Observe, Ask Why
●
●
●
●

Don’t tell what it is but get their impressions of what
it is. The more they talk the better.
Set the scenario up.
Tell them that there are no right or wrong answers.
Similar to interviewing someone for a story, remain
objective and try to understand why they think and do
certain things, and what would make it a better
experience.

Short Run Testing
●

●

After just 2 or 3 people, similar points of feedback
will probably emerge, pointing out what works and
what doesn’t work.
Resolve by making small changes that make a big
difference.

Quality Check Revisions
●

Confirm if changes solved issues by quick testing again
with 2-3 new people.

Iteration #1

Participant #1:
●

●

●

Understood graphic talking about symptoms
of heat illness, what to do is not as
clear on both sides because of stars.
CALL 9–1–1 is important as first step on
heat stroke side. May Lose Consciousness
is more of a symptom.
Illustration is clear.

Participant #2:
●

Spanish is good, but the italics makes it
look secondary, a little hard to read.

Participant #3:
●

Most important thing to do is call 9–1–1
when having a heat stroke, so that should
be first.

Iteration #2

Participant #4:
●

●

First impression is to be aware of heat
illness, notices call to action to either
stay cool or call 9–1–1.
Self-explanatory, pretty clear graphic.

Participant #5:
●
●
●

First sees body graphic, likes the round
softness of it, not overly serious.
Understood symptoms and graphics from both
sides.
Looks advisory.

First Iteration

Published Iteration

The “Paul Test”
ProPublica’s quick,
in-house testing

●

●

Similar to WNYC’s
process: quick and
in-house
Quickly figure out what
is and isn’t working

Longer Time Scale

Recruit Users to Test Your Stuff
●
●

At ProPublica, we put a call out on social media accounts
Also reached out to our newsletter subscribers via email
○

More diverse group than our Twitter audience

Find people who are not journalists.

ProPublica’s Tech Setup
●
●
●
●
●

Schedule sessions for 3-6 people in a morning or
afternoon
Allow about 30 minutes per session
Set up Join Me for screen-sharing (bonus: recording!)
Have the participant call into the conference line for
audio
Plan a few minutes afterward to debrief

Pick Someone to Conduct the User Test
●

●

It’s easier to have someone else test your project
(though whoever’s working on it should sit in on the
session)
Plan time to debrief afterward
○

Maybe over lunch?

How Many People Should You Test?
●
●
●

We shoot for 3-5 people
Note any patterns among participants
Watch for problems you weren’t expecting

“Testing one user is 100 percent better than
testing none.” —Steve Krug

Before the Interview
●

Decide what to test
○

●

Figure out what tasks will help you answer your questions
○

●

Have one or two specific things in mind
Should be things real people would use your project for

Be open to problems you didn’t anticipate

Conducting the Interview
●
●
●

Start with an icebreaker
Tell them there are no right or wrong answers
Great question to start with: “How would you describe
what you’re looking at to someone who can’t see it?”

Conducting the Interview
●
●

Give the participant context and ask them to complete one
of your tasks
Or you can show something with relatively little context
and ask them to talk about it
○

Like confidence intervals. They got it!

Gathering Feedback
●

Assume everything your user tells you is valid
○

●

Let your user fail
○

●

Don’t argue! Don’t show them how to do it!
It hurts, but you’ll learn a lot

“Shut the hell up” and listen. —Laura Klein

Take Notes on Everything!
●

Including nonverbal things
○

●

Even if the session is remote

Quotes are good for selling user testing to stakeholders

Notes From a User
Testing Session
●

●
●

Shows how users
expected to be able to
enter just ZIP code
instead of full address
Notes full pathways
users took
Draws on several user
testing sessions to
spot patterns

—Notes courtesy of Sisi Wei.

Wrap It Up
●
●
●

“What do you think of the information you just saw?”
“Is there anything else you’d like to tell me about what
we looked at?”
Heartfelt thanks!

A Few Things We’ve
Tested at ProPublica
●
●
●
●

Surgeon Scorecard
Cruise Control
Losing Ground
Hell and High Water

Photo by Edwin Torres for ProPublica

Surgeon Scorecard
●
●
●

Tested twice, a week
apart
First test helped
inform homepage layout
Do users get the three
search tabs?

What We Tested
●

●

Do users get the three
search functions on the
search field?
Do they know what a
confidence interval is?

Cruise Control
●

Immediately got
actionable feedback:
Users weren’t seeing
the lookup tool

Quick Fix!
●

●

Moved that lookup box
to a different part of
the page
Users saw it right away

Test → iterate → retest = ideal

Congressional Primary
Election Guide, WNYC

Form vs. Filter

NY Primary Election
Guide, WNYC

General Election
Guide, WNYC

Steps for User Testing:

1. Make an Outline of Testing Objectives
2. Script an Interview Guide
3. Select & Confirm Participants
4. Conduct the Usability Test
5. Summarize Findings and Next Steps

Things we wanted to know
Determine if users understand the election guide
features and iconography:
●
●
●
●
●

Is finding information about each race clear?
Is finding information about each candidate
clear?
Is the election guide intuitive and easy to use?
How do users react to the guide colors, photos
and illustration?
Are the icons understandable?

Observe:
● Any points of frustration or distress
● Does the election guide make sense to them?
● Do they come away more knowledgeable?

Screener for selecting participants, choose a
range of participants as diverse as possible:

The Interview Guide
Warm-up Script
Welcome. Thanks for coming in today. I’m a researcher
and it’s my job to learn about you and observe how and
why people use online tools. This is not a standard
test, so there are no right or wrong answers or
actions. Please speak openly and honestly throughout
the session, and just imagine you’re putting your
brain on speakerphone.
Ask permission to record.

The Interview Guide
Before we start
●
●
●
●

●

What are the top websites you visit the most?
What do you know about WNYC?
Have you ever visited their website?
How often do you visit?
○ For what reason? (Podcasts, streaming, on air
(live), donation, etc.)
Do you consider yourself an informed voter?

The Interview Guide
Show the Prototype
Imagine Election Day is coming up in a few days and
you’re going to vote. You see this link to an
election guide on your social media feed, you click
and see this.
1.

“What are you seeing?”

2.

“What would you do next?”

The Interview Guide
Follow up questions
1.
2.

On a scale from 1 to 10, how likely are you to use this?
Why?

●
●

What do you like best about this experience?
What do you like least about this experience? Was there
anything confusing?
What information would you want to know about voting in
elections?
Did you think there was information missing from this
guide?
What would be your next step after using this guide?

●
●
●

Now We Can Try It
An Exercise in User Testing

What We’re Going to Do
●
●
●
●
●
●
●

Choose a project to test.
Write down what you generally want to test.
Find a partner.
Run a test, with one of you as the user and one as the
interviewer.
Swap roles and run the test again.
Talk through your findings.
Optional: Share feedback with the group!

Bring up a project you’re working on or have published already.
Or open an internet browser and go to www.travelocity.com.

Write down what you want to test — 2 minutes

Find a partner

Run a test, with one of you as the user and one
as the interviewer — 5 minutes

Swap roles and run the test again — 5 minutes

Talk through your findings — 5 minutes

Watch someone try to use the thing you made,
when there’s still time to fix it.

“It’s a gateway drug to empathy with the
audience.” —David Sleight

What else could we user test?
●
●
●

User testing isn’t limited to what we talked about
Audio projects? Script writing? Story comprehension?
Email! Internal documentation! This talk!

Go forth and talk to the people you’re designing for
… to make something your users really understand.

Thank you!
Feel free to reach out.

Hannah: hannah.birch@propublica.org, @hannahsbirch
Clarisa: cdiaz@wnyc.org, @Clarii_D

Resources
General overview:
○
Usability Testing Demystified, by Dana Chisnell. http://bit.ly/2mN9U
○
Never Show a Design You Haven’t Tested on Users, by Ida Aalen. http://bit.ly/2mNp9Oh
○
Usability Testing. Oh, The Things You Can Learn., by Jared Spool. http://bit.ly/2mvKwaA
○
Two out of two news organizations recommend user research, by Laura Hazard Owen.
http://bit.ly/2mvE97d
○
The Myth of Usability Testing, by Robert Hoekman Jr. http://bit.ly/2mvIKGy
○
Don’t Make Me Think, Revisited (book), by Steve Krug. New Riders Publishing, 2014.
http://bit.ly/2lYEEns
○
You say "potato," I say "focus group" (video), by Steve Krug. http://bit.ly/2mHwkIv
○
How Usability Testing Can Improve News Stories, by Clarisa Diaz. http://bit.ly/2leS9SQ
The testing process:
○
Collaborative User Testing: Less Bias, Better Research, by Alla Kholmatova.
http://bit.ly/2mNsAVi
○
Improving Your Website Usability Tests, by Damian Rees. http://bit.ly/2lVWEAv
○
Quick and Dirty Remote User Testing, by Nate Bolt. http://bit.ly/2mNcRp0
○
A Guide To Simple And Painless Mobile User Testing, by Colman Walsh. http://bit.ly/2mbj5lq
○
Testing Content, by Angela Colter. http://bit.ly/2lB7uJC
○
UX for Lean Startups: Faster, Smarter User Experience Research and Design, by Laura Klein.
http://oreil.ly/2mNdzTc

Resources
“Guerrilla” user testing:
○
The Art of Guerrilla Usability Testing, by David Peter Simon. http://bit.ly/2mNcSJE
○
Meet the User research team, from the Government Digital Service’s blog at gov.uk.
http://bit.ly/2mgDFl7
More formalized/in-depth testing methods:
○
Beyond Usability Testing, by Devan Goldstein. http://bit.ly/2lujiwb
○
Inside Your Users’ Minds: The Cultural Probe, by Ruth Stalker-Firth. http://bit.ly/2leTOrC
Sharing unfinished work:
○
Sharing Our Work: Testing and Feedback in Design, by Jessica Harllee. http://bit.ly/2lueQ0q
Public speaking:
○
Demystifying Public Speaking, by Lara Hogan. A Book Apart, 2016. http://bit.ly/2lBCWHp
○
SpeakerCamp, A Self-paced Workshop for Planning, Pitching, Preparing, and Presenting at
Conferences, by Russ Unger and Samantha Starmer. New Riders Publishing, 2013.
http://bit.ly/2mbeBv8

