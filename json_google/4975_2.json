```json
{
  "id": "4975_2",
  "authors": [
    {
      "name": "Sharad Goel",
      "email": null,
      "affiliation": "Stanford University"
    }
  ],
  "conference": "Not Listed",
  "year": "Not Listed",
  "title": "Algorithmic fairness",
  "description": "Algorithms like COMPAS are used to predict the likelihood of a defendant committing a crime. However, these algorithms can be biased against certain groups of people, such as black defendants. This can lead to unfair outcomes, such as black defendants being detained more often than white defendants.",
  "keywords": ["algorithmic fairness", "COMPAS", "pre-trial detention", "race"]
}
```
