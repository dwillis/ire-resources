Sure, here is a JSON object based on the contents of the text:

```json
{
  "id": 5262,
  "authors": [
    {
      "name": "Joshua Schneyer",
      "email": "joshua.schneyer@thomsonreuters.com",
      "affiliation": "Reuters"
    }
  ],
  "conference": "IRE",
  "year": "2017",
  "title": "Where are kids being poisoned? Tracking lead poisoning locally and nationally",
  "description": "After news broke of the Flint contamination crisis, Reuters sought to pinpoint other areas where exposure might be just as bad or worse, including communities unaware of local exposure risks. We launched a broad data-gathering project, seeking childhood blood lead test results at the neighborhood level across the country. When we published an investigation last December, its main findings were: “Flint is no aberration. In fact, it doesn’t even rank among the most dangerous lead hotspots in America. In all, Reuters found nearly 3,000 areas with recently recorded lead poisoning rates at least double those in Flint during the peak of that city’s contamination crisis. And more than 1,100 of these communities had a rate of elevated blood tests at least four times higher.” By areas, we meant zip codes or census tracts. In most cases, publicly available data on childhood blood lead exposure has been national, state or countywide, too broad to identify troubled neighborhoods and track health disparities at the local level. We knew we needed more granular data. By elevated, we meant a blood test on a child under six at or above 5 micrograms per deciliter of lead, the CDC’s current threshold for an elevated level warranting a public health response. Some states define this level as lead poisoning, others put the poisoning cutoff higher or don’t define it. There’s no safe level of lead in blood, and even at 5 micrograms/deciliter the impacts can include lower IQ, developmental and attentional disorders, and other irreversible health impacts. During the peak of Flint’s crisis, the CDC found 5 percent of small children tested there had high levels. In some neighborhoods across the country – including spots in cities like Cleveland, Philadelphia and Buffalo – local data shows the rate of children who tested high in recent years was 40-50%, or nearly 10-fold Flint’s rate. Decades of U.S. efforts to eradicate lead poisoning have made great progress in lowering average lead levels among children, but the job is far from complete. Many states (justifiably) boast of a sharp reduction in the percentage of children who test high, but this doesn’t mean there aren’t lingering exposure hotspots where the numbers are far higher. Localized data can help identify these areas. We got neighborhood data covering about two thirds of US states and three fourths of the child population, mapping it out in an interactive: http://www.reuters.com/investigates/graphics/leadwater/en/ This data has limitations (for instance, many children are never tested for lead), but it can help raise community awareness, pinpoint areas in need of more resources, testing and lead remediation, and challenge the narrative that lead poisoning is a bygone problem. This reporting, in many localities, could go much further than we’ve been able to take it. Virtually all states have the ability and tools to boost surveillance of lead poisoning and share the data. We make the case that all of them should be sharing localized testing data. In seeking this type of data from local, state or federal health authorities – on lead exposure or other health metrics – here are some of the roadblocks reporters encounter: a) Hyper-local health data, with small sample sizes, can run up against privacy/HIPAA concerns b) States (and even counties) take different approaches to gathering the data and reporting it, making comparisons challenging c) Health departments lack funding for robust surveillance efforts – some don’t geocode it d) Officials can be reluctant to release data that show their efforts to combat exposure to lead (or other toxins) are lacking in troubled neighborhoods e) The data often contains errors, or sample sizes are too small to draw valid epidemiological conclusions about risk Many of these challenges can be overcome: a) Government agencies can de-identify privacy-protected data b) Reporters, with help from epidemiologists and health researchers, can build databases and frameworks that maximize the comparability of disparate data-sets, while explaining the limitations they face (in a methodology or “nerd” box attached to the story) c) It’s crucial to point out areas where health surveillance has been lousy, due to funding gaps or other lapses. Health officials are often forthcoming about these problems, and reporting on it can help them get funding or improve surveillance d) If the data exists in public records, and doesn
